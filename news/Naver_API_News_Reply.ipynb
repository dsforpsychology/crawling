{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc80cd9",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 댓글 크롤링 \n",
    "### 1. 키워드로 뉴스 리스트 수집 \n",
    "### 2. 링크별 댓글 수집 \n",
    "### 3. CSV로 저장  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e661e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilove\\AppData\\Local\\Temp\\ipykernel_28428\\434910140.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 키워드를 입력해주세요:정신질환\n",
      "\n",
      "크롤링을 끝낼 페이지 위치를 입력해주세요. (기본값:1, 최대값:100):1\n",
      "\n",
      " 1 ~  1 페이지 까지 크롤링을 진행 합니다\n",
      "\n",
      "한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):10\n",
      "\n",
      "한번에 가져올 페이지 :  10 페이지\n",
      "https://openapi.naver.com/v1/search/news?query=%EC%A0%95%EC%8B%A0%EC%A7%88%ED%99%98&start=1&display=11\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# WebDriver Setting\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "\n",
    "# selenium으로 검색 페이지 불러오기 #\n",
    "naver_urls = []\n",
    "pub_dates = []\n",
    "\n",
    "# Naver API key 입력\n",
    "client_id = '' \n",
    "client_secret = ''\n",
    "\n",
    "# 검색어 입력\n",
    "keword = input(\"검색할 키워드를 입력해주세요:\")\n",
    "encText = urllib.parse.quote(keword)\n",
    "\n",
    "# 검색을 끝낼 페이지 입력\n",
    "end = input(\"\\n크롤링을 끝낼 페이지 위치를 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "if end == \"\":\n",
    "    end = 1\n",
    "else:\n",
    "    end = int(end)\n",
    "print(\"\\n 1 ~ \", end, \"페이지 까지 크롤링을 진행 합니다\")\n",
    "\n",
    "# 한번에 가져올 페이지 입력\n",
    "display = input(\"\\n한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):\")\n",
    "if display == \"\":\n",
    "    display = 10\n",
    "else:\n",
    "    display = int(display)\n",
    "print(\"\\n한번에 가져올 페이지 : \", display, \"페이지\")\n",
    "\n",
    "\n",
    "for start in range(end):\n",
    "    url = \"https://openapi.naver.com/v1/search/news?query=\" + encText + \"&start=\" + str(start+1) + \"&display=\" + str(display+1) # JSON 결과\n",
    "    print(url)\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        data = json.loads(response_body.decode('utf-8'))['items']\n",
    "        for row in data:\n",
    "            if('news.naver' in row['link']):\n",
    "                naver_urls.append(row['link'])\n",
    "                pub_dates.append(row['pubDate'])\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "\n",
    "###naver 기사 본문 및 제목 가져오기###\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "titles = []\n",
    "contents = []\n",
    "comments_texts = []\n",
    "for i in naver_urls:\n",
    "    original_html = requests.get(i, headers=headers)\n",
    "    html = BeautifulSoup(original_html.text, \"html.parser\")\n",
    "    # 뉴스 제목 가져오기\n",
    "    title = html.select(\"div#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "    # list합치기\n",
    "    title = ''.join(str(title))\n",
    "    # html태그제거\n",
    "    pattern1 = '<[^>]*>'\n",
    "    title = re.sub(pattern=pattern1, repl='', string=title)\n",
    "    titles.append(title)\n",
    "\n",
    "    # 뉴스 본문 가져오기\n",
    "\n",
    "    content = html.select(\"div#dic_area\")\n",
    "\n",
    "    # 기사 텍스트만 가져오기\n",
    "    # list합치기\n",
    "    content = ''.join(str(content))\n",
    "\n",
    "    # html태그제거 및 텍스트 다듬기\n",
    "    content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "    pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "    content = content.replace(pattern2, '')\n",
    "    contents.append(content)\n",
    "\n",
    "    # 댓글 가져오기\n",
    "    driver.get(i)\n",
    "    time.sleep(1)  # 대기시간 변경 가능\n",
    "    # 네이버 댓글 눌러서 댓글 가져오기#\n",
    "    a = driver.find_element(By.CSS_SELECTOR, 'a._COMMENT_COUNT_VIEW')\n",
    "    \n",
    "    # 댓글 더보기 클릭\n",
    "    a.click()\n",
    "\n",
    "    # 대기시간 변경 가능\n",
    "    time.sleep(3)  \n",
    "\n",
    "    # 네이버 뉴스 댓글 가져오기\n",
    "    html = driver.page_source\n",
    "    c_soup = BeautifulSoup(html)\n",
    "\n",
    "    comments = c_soup.select('span.u_cbox_contents')\n",
    "    comments_text = ', '.join([comment.text.strip() for comment in comments])\n",
    "    comments_texts.append(comments_text)\n",
    "\n",
    "\n",
    "# 데이터프레임으로 정리\n",
    "import pandas as pd\n",
    "\n",
    "news_df = pd.DataFrame({'title': titles, 'link': naver_urls, 'content': contents, 'comments': comments_texts,'date': pub_dates})\n",
    "\n",
    "news_df.to_csv('news.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf26f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
